{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efkaJpTgtqpe"
      },
      "outputs": [],
      "source": [
        "pip install grad-cam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UU13Zbo3uMG1"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRYAsL5GtUh2",
        "outputId": "4a4ab118-9b0c-4286-d634-dfb2756d0852"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "import time\n",
        "from pytorch_grad_cam import GradCAM\n",
        "from pytorch_grad_cam import ScoreCAM\n",
        "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
        "import tqdm\n",
        "import torch.nn.functional as F\n",
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "D7dCzV3puDV4"
      },
      "outputs": [],
      "source": [
        "# GPU ÏÇ¨Ïö© ÏÑ§Ï†ï\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "XCH1L55LtxJr"
      },
      "outputs": [],
      "source": [
        "class DenseNetWithRelu0(nn.Module):\n",
        "    def __init__(self, num_classes=7):\n",
        "        super().__init__()\n",
        "        base = models.densenet121(pretrained=True)\n",
        "        self.features = base.features\n",
        "        self.classifier = nn.Linear(1024, num_classes)\n",
        "\n",
        "        # relu0ÍπåÏßÄ Î™ÖÏãúÏ†ÅÏúºÎ°ú Ï†ëÍ∑º Í∞ÄÎä•ÌïòÎèÑÎ°ù\n",
        "        self.conv0 = self.features.conv0\n",
        "        self.norm0 = self.features.norm0\n",
        "        self.relu0 = self.features.relu0\n",
        "        self.pool0 = self.features.pool0\n",
        "        self.dense1 = self.features.denseblock1\n",
        "        self.trans1 = self.features.transition1\n",
        "        self.dense2 = self.features.denseblock2\n",
        "        self.trans2 = self.features.transition2\n",
        "        self.dense3 = self.features.denseblock3\n",
        "        self.trans3 = self.features.transition3\n",
        "        self.dense4 = self.features.denseblock4\n",
        "        self.norm5 = self.features.norm5\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv0(x)\n",
        "        x = self.norm0(x)\n",
        "        x = self.relu0(x)\n",
        "        self.feature_map_relu0 = x  #Ï†ÄÏû•\n",
        "\n",
        "        x = self.pool0(x)\n",
        "        x = self.dense1(x)\n",
        "        x = self.trans1(x)\n",
        "        x = self.dense2(x)\n",
        "        x = self.trans2(x)\n",
        "        x = self.dense3(x)\n",
        "        x = self.trans3(x)\n",
        "        x = self.dense4(x)\n",
        "        x = self.norm5(x)\n",
        "\n",
        "        out = F.adaptive_avg_pool2d(x, (1, 1)).view(x.size(0), -1)\n",
        "        return self.classifier(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "g3HQvYcRt46L",
        "outputId": "72bf5f9e-e44f-4978-9f14-577cb10a7679"
      },
      "outputs": [],
      "source": [
        "dens_model = DenseNetWithRelu0(num_classes=7).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "2IBAW_Not7Iw"
      },
      "outputs": [],
      "source": [
        "#pthÌååÏùºÍ≤ΩÎ°ú ÏàòÏ†ï ÌïÑÏöî\n",
        "dens_model.load_state_dict(torch.load('', map_location=device))\n",
        "dens_model.to(device)\n",
        "dens_model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "u67oeAULuijx"
      },
      "outputs": [],
      "source": [
        "target_layer = dens_model.features.relu0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "UKAWUwsbuTzK"
      },
      "outputs": [],
      "source": [
        "#ptÌååÏùºÍ≤ΩÎ°ú ÏàòÏ†ï ÌïÑÏöî\n",
        "seg_model = YOLO('')  # ÎòêÎäî yolov8m-seg.pt, yolov8n-seg.pt Îì±\n",
        "seg_model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czQnzm6lwGpi"
      },
      "outputs": [],
      "source": [
        "#csvÌååÏùºÍ≤ΩÎ°ú ÏàòÏ†ï ÌïÑÏöî\n",
        "import pandas as pd\n",
        "df_density = pd.read_csv('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "KyQ2k_TvxFHC"
      },
      "outputs": [],
      "source": [
        "mean = [0.43755555152893066, 0.39420410990715027, 0.3537991940975189]\n",
        "std = [0.21359124779701233, 0.19734203815460205, 0.18219676613807678]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "2NhnZzzEEyva"
      },
      "outputs": [],
      "source": [
        "# ÏõêÎ≥∏, ÎßàÏä§ÌÅ¨, Ï∫†\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "from pytorch_grad_cam import ScoreCAM\n",
        "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
        "from scipy.ndimage import gaussian_filter\n",
        "\n",
        "def generate_elliptical_roi(shape=(224, 224), x_ratio=0.5, y_ratio=0.35):\n",
        "    h, w = shape\n",
        "    Y, X = np.ogrid[:h, :w]\n",
        "    cy, cx = h // 2, w // 2\n",
        "    rx = int(w * x_ratio)\n",
        "    ry = int(h * y_ratio)\n",
        "    mask = ((X - cx)**2 / rx**2 + (Y - cy)**2 / ry**2) <= 1\n",
        "    return mask.astype(np.float32)\n",
        "\n",
        "def predict_and_visualize_all(\n",
        "    image_path, class_model, seg_model,\n",
        "    target_layer, df_density,\n",
        "    mask_dir=None, device='cuda', cam_alpha=0.6, cam_thresh=0.6\n",
        "):\n",
        "    class_model.to(device).eval()\n",
        "    seg_model.to(device).eval()\n",
        "\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image_resized = image.resize((224, 224))\n",
        "    img_np = np.array(image_resized)\n",
        "    img_np_original = np.array(image)\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std)\n",
        "    ])\n",
        "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    results = seg_model.predict(source=image_path, save=False, imgsz=640, conf=0.25)\n",
        "    result = results[0]\n",
        "\n",
        "    mask_h, mask_w = result.orig_shape\n",
        "    color_mask = np.zeros((mask_h, mask_w, 3), dtype=np.uint8)\n",
        "    roi_mask = np.zeros((mask_h, mask_w), dtype=np.uint8)\n",
        "\n",
        "    if result.masks is not None:\n",
        "        masks = result.masks.data.cpu().numpy()\n",
        "        classes = result.boxes.cls.cpu().numpy().astype(int)\n",
        "        for i, class_id in enumerate(classes):\n",
        "            mask = masks[i]\n",
        "            binary_mask = (mask > 0.5).astype(np.uint8)\n",
        "            color = (0, 255, 0) if class_id == 1 else (0, 0, 255)\n",
        "            for c in range(3):\n",
        "                color_mask[..., c][binary_mask == 1] = color[c]\n",
        "            roi_mask[binary_mask == 1] = 1\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = class_model(image_tensor)\n",
        "        pred_class = torch.argmax(logits, dim=1).item()\n",
        "\n",
        "    cam_extractor = ScoreCAM(model=class_model, target_layers=[target_layer])\n",
        "    grayscale_cam = cam_extractor(input_tensor=image_tensor, targets=[ClassifierOutputTarget(pred_class)])[0]\n",
        "\n",
        "    grayscale_cam -= grayscale_cam.min()\n",
        "    grayscale_cam /= grayscale_cam.max() + 1e-6\n",
        "    grayscale_cam = np.clip(grayscale_cam, 0.1, 1.0)     # Íµ¨Î©ç Î∞©ÏßÄ\n",
        "    grayscale_cam = gaussian_filter(grayscale_cam, sigma=3)     # Î∏îÎü¨ ÏôÑÌôî\n",
        "\n",
        "    # Threshold + closing\n",
        "    cam_mask = (grayscale_cam >= cam_thresh).astype(np.uint8)\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (21, 21))\n",
        "    cam_mask_closed = cv2.morphologyEx(cam_mask, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "    # ROI ÎßàÏä§ÌÅ¨ ‚Üí closing Ï†ÅÏö©\n",
        "    roi_resized = cv2.resize(roi_mask.astype(np.uint8), (224, 224), interpolation=cv2.INTER_NEAREST)\n",
        "    roi_closed = cv2.morphologyEx(roi_resized, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "    # Îëê ÎßàÏä§ÌÅ¨ Î™®Îëê CAMÏóê Í≥±ÌïòÍ∏∞\n",
        "    grayscale_cam *= roi_closed.astype(np.float32)\n",
        "    grayscale_cam *= cam_mask_closed.astype(np.float32)\n",
        "\n",
        "    # Î∂ÄÎìúÎü¨Ïö¥ ÎßàÎ¨¥Î¶¨ closing\n",
        "    kernel_smooth = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (13, 13))\n",
        "    grayscale_cam = cv2.morphologyEx(grayscale_cam.astype(np.float32), cv2.MORPH_CLOSE, kernel_smooth)\n",
        "\n",
        "    # Í≤ΩÍ≥Ñ Î∂ÄÎìúÎüΩÍ≤å ÎßåÎì§Í∏∞ Ï∂îÍ∞Ä\n",
        "    grayscale_cam = cv2.GaussianBlur(grayscale_cam, (15, 15), sigmaX=3)\n",
        "\n",
        "    # thresholding\n",
        "    grayscale_cam = np.where(grayscale_cam >= 0.5, grayscale_cam, 0)\n",
        "\n",
        "    img_np_norm = img_np.astype(np.float32) / 255.0\n",
        "    cam_overlay = show_cam_on_image(img_np_norm, grayscale_cam, use_rgb=True, image_weight=1 - cam_alpha)\n",
        "\n",
        "    # --- 4. Density score Í≥ÑÏÇ∞ (% Í∏∞Î∞ò, clipping ÏóÜÏù¥) ---\n",
        "    hair_mask = np.all(color_mask == [0, 255, 0], axis=-1)\n",
        "    roi_mask_bool = (color_mask != [0, 0, 0]).any(axis=-1)\n",
        "    hair_percent = (hair_mask.sum() / (roi_mask_bool.sum() + 1e-6)) * 100  # ‚Üê % Í∏∞Î∞ò\n",
        "\n",
        "    row = df_density[df_density['class'] == (pred_class + 1)].iloc[0]\n",
        "    class_avg = row['avg_hair_ratio']\n",
        "\n",
        "    class1_avg = df_density[df_density['class'] == 1]['avg_hair_ratio'].values[0]\n",
        "    class7_avg = df_density[df_density['class'] == 7]['avg_hair_ratio'].values[0]\n",
        "    abs_score = ((hair_percent - class7_avg) / (class1_avg - class7_avg)) * 100  # ‚Üê clipping Ï†úÍ±∞, epsilon Ï†úÍ±∞\n",
        "\n",
        "    cam_overlay_resized = cv2.resize(cam_overlay, (mask_w, mask_h), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "    plt.figure(figsize=(20, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(img_np_original)\n",
        "    plt.title(\"Original Image\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(cam_overlay_resized)\n",
        "    plt.title(f\"CAM Overlay\\nClass {pred_class+1} | Hair %: {hair_percent:.2f} | Score: {abs_score:.1f}\\n\"\n",
        "              f\"‚Üí Class {pred_class+1} Avg: {class_avg:.2f}%\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return {\n",
        "        'pred_class': pred_class + 1,\n",
        "        'hair_percent': hair_percent,\n",
        "        'abs_score': abs_score,\n",
        "        'class_avg': class_avg\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "bQgL7Kk_DE20"
      },
      "outputs": [],
      "source": [
        "def predict_and_visualize_all(\n",
        "    image_path, class_model, seg_model,\n",
        "    target_layer, df_density,\n",
        "    mask_dir=None, device='cuda', cam_alpha=0.6, cam_thresh=0.6\n",
        "):\n",
        "    class_model.to(device).eval()\n",
        "    seg_model.to(device).eval()\n",
        "\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image_resized = image.resize((224, 224))\n",
        "    img_np = np.array(image_resized)\n",
        "    img_np_original = np.array(image)\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std)\n",
        "    ])\n",
        "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    results = seg_model.predict(source=image_path, save=False, imgsz=640, conf=0.25)\n",
        "    result = results[0]\n",
        "\n",
        "    mask_h, mask_w = result.orig_shape\n",
        "    color_mask = np.zeros((mask_h, mask_w, 3), dtype=np.uint8)\n",
        "    roi_mask = np.zeros((mask_h, mask_w), dtype=np.uint8)\n",
        "\n",
        "    if result.masks is not None:\n",
        "        masks = result.masks.data.cpu().numpy()\n",
        "        classes = result.boxes.cls.cpu().numpy().astype(int)\n",
        "        for i, class_id in enumerate(classes):\n",
        "            mask = masks[i]\n",
        "            binary_mask = (mask > 0.5).astype(np.uint8)\n",
        "            color = (0, 255, 0) if class_id == 1 else (0, 0, 255)\n",
        "            for c in range(3):\n",
        "                color_mask[..., c][binary_mask == 1] = color[c]\n",
        "            roi_mask[binary_mask == 1] = 1\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = class_model(image_tensor)\n",
        "        pred_class = torch.argmax(logits, dim=1).item()\n",
        "\n",
        "    cam_extractor = ScoreCAM(model=class_model, target_layers=[target_layer])\n",
        "    grayscale_cam = cam_extractor(input_tensor=image_tensor, targets=[ClassifierOutputTarget(pred_class)])[0]\n",
        "\n",
        "    grayscale_cam -= grayscale_cam.min()\n",
        "    grayscale_cam /= grayscale_cam.max() + 1e-6\n",
        "    grayscale_cam = np.clip(grayscale_cam, 0.1, 1.0)\n",
        "    grayscale_cam = gaussian_filter(grayscale_cam, sigma=3)\n",
        "\n",
        "    cam_mask = (grayscale_cam >= cam_thresh).astype(np.uint8)\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (21, 21))\n",
        "    cam_mask_closed = cv2.morphologyEx(cam_mask, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "    roi_resized = cv2.resize(roi_mask.astype(np.uint8), (224, 224), interpolation=cv2.INTER_NEAREST)\n",
        "    roi_closed = cv2.morphologyEx(roi_resized, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "    grayscale_cam *= roi_closed.astype(np.float32)\n",
        "    grayscale_cam *= cam_mask_closed.astype(np.float32)\n",
        "\n",
        "    kernel_smooth = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (13, 13))\n",
        "    grayscale_cam = cv2.morphologyEx(grayscale_cam.astype(np.float32), cv2.MORPH_CLOSE, kernel_smooth)\n",
        "    grayscale_cam = cv2.GaussianBlur(grayscale_cam, (15, 15), sigmaX=3)\n",
        "    grayscale_cam = np.where(grayscale_cam >= 0.5, grayscale_cam, 0)\n",
        "\n",
        "    img_np_norm = img_np.astype(np.float32) / 255.0\n",
        "    cam_overlay = show_cam_on_image(img_np_norm, grayscale_cam, use_rgb=True, image_weight=1 - cam_alpha)\n",
        "\n",
        "    # --- 4. Density score Í≥ÑÏÇ∞ ---\n",
        "    hair_mask = np.all(color_mask == [0, 255, 0], axis=-1)\n",
        "    roi_mask_bool = (color_mask != [0, 0, 0]).any(axis=-1)\n",
        "    hair_percent = (hair_mask.sum() / (roi_mask_bool.sum() + 1e-6)) * 100\n",
        "\n",
        "    class1_avg = df_density[df_density['class'] == 1]['avg_hair_ratio'].values[0]\n",
        "    class7_avg = df_density[df_density['class'] == 7]['avg_hair_ratio'].values[0]\n",
        "\n",
        "    abs_score = ((hair_percent - class7_avg) / (class1_avg - class7_avg)) * 100\n",
        "\n",
        "    # üîÑ class ÌèâÍ∑†ÎèÑ ÎèôÏùº Í∏∞Ï§ÄÏÑ†ÏúºÎ°ú ÏÑ†ÌòïÎ≥¥Í∞Ñ\n",
        "    row = df_density[df_density['class'] == (pred_class + 1)].iloc[0]\n",
        "    class_avg = row['avg_hair_ratio']\n",
        "    class_avg_score = ((class_avg - class7_avg) / (class1_avg - class7_avg)) * 100\n",
        "\n",
        "    cam_overlay_resized = cv2.resize(cam_overlay, (mask_w, mask_h), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "    plt.figure(figsize=(20, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(img_np_original)\n",
        "    plt.title(\"Original Image\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(cam_overlay_resized)\n",
        "    plt.title(f\"CAM Overlay\\nClass {pred_class+1} | Hair %: {hair_percent:.2f} | Score: {abs_score:.1f}\\n\"\n",
        "              f\"‚Üí Class {pred_class+1} Avg Score: {class_avg_score:.1f}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return {\n",
        "        'pred_class': pred_class + 1,\n",
        "        'hair_percent': hair_percent,\n",
        "        'abs_score': abs_score,\n",
        "        'class_avg_score': class_avg_score\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "h5jN1lYkE0ra",
        "outputId": "2ac99440-f4cc-4c89-9ebb-44631b156585"
      },
      "outputs": [],
      "source": [
        "result = predict_and_visualize_all(\n",
        "    image_path=\"\",\n",
        "    class_model=dens_model,                      # classification model\n",
        "    seg_model=seg_model,                         # segmentation model\n",
        "    target_layer=dens_model.features.relu0,      # CAMÏóê ÏÇ¨Ïö©Ìï† layer\n",
        "    df_density=df_density,                       # classÎ≥Ñ Î∞ÄÎèÑ Í∏∞Ï§Ä DataFrame\n",
        "    device='cuda',\n",
        "    cam_alpha=0.3,\n",
        "    cam_thresh=0.6\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
